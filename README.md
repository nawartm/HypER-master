# ğŸ§  HypER & Friends â€” Apprentissage de ReprÃ©sentations pour Graphes de Connaissances

> ğŸ¯ *Objectif : Apprendre Ã  reprÃ©senter les entitÃ©s (ex: â€œParisâ€, â€œFranceâ€) et les relations (ex: â€œcapitale_deâ€) sous forme de vecteurs, pour prÃ©dire des faits manquants dans un graphe de connaissances.*

Ce projet implÃ©mente et compare plusieurs modÃ¨les dâ€™**embeddings de graphes de connaissances** (Knowledge Graph Embeddings) :
- **HypER** â€” ModÃ¨le convolutionnel avec filtres hyper-rÃ©seaux
- **ConvE** â€” ModÃ¨le convolutionnel 2D
- **DistMult** â€” ModÃ¨le multiplicatif simple
- **ComplEx** â€” Extension complexe de DistMult (gÃ¨re les relations asymÃ©triques)
- **HypE** â€” Version antÃ©rieure de HypER

Les modÃ¨les sont entraÃ®nÃ©s et Ã©valuÃ©s sur des benchmarks standards :
- `FB15k-237` â€” sous-ensemble filtrÃ© de Freebase
- `WN18RR` â€” sous-ensemble de WordNet sans fuites inverses
- `FB15k`, `WN18` â€” versions originales (moins recommandÃ©es)

---

## ğŸ“š Contexte Scientifique

Dans un **graphe de connaissances**, les faits sont reprÃ©sentÃ©s sous forme de triplets :  
> `(sujet, relation, objet)` â†’ ex: `(Paris, capitale_de, France)`

Lâ€™objectif est de **prÃ©dire lâ€™objet manquant** dans un triplet incomplet :  
> `(Paris, capitale_de, ?)` â†’ doit prÃ©dire `France`

Câ€™est ce quâ€™on appelle la **complÃ©tion de liens (link prediction)**.

Les modÃ¨les apprennent des **reprÃ©sentations vectorielles** (embeddings) pour chaque entitÃ© et relation, puis combinent ces vecteurs pour prÃ©dire la probabilitÃ© quâ€™un triplet soit vrai.

---

## ğŸ‘¥ Pour qui est ce projet ?

| Public | Ce quâ€™il y trouvera |
|--------|----------------------|
| ğŸ‘©â€ğŸ“ **Ã‰tudiants en IA / NLP / Graph ML** | Une implÃ©mentation claire de modÃ¨les avancÃ©s, parfaite pour apprendre ou comparer les architectures. |
| ğŸ‘¨â€ğŸ”¬ **Chercheurs / IngÃ©nieurs en IA** | Un code fonctionnel, modulaire, facile Ã  Ã©tendre ou adapter pour de nouvelles expÃ©riences. |
| ğŸ‘©â€ğŸ’» **DÃ©veloppeurs curieux** | Un exemple concret dâ€™apprentissage de reprÃ©sentations sÃ©mantiques avec PyTorch. |
| ğŸ‘” **Managers / Curieux** | Une dÃ©monstration de comment les machines â€œcomprennentâ€ les relations entre concepts du monde rÃ©el. |

---

## âš™ï¸ FonctionnalitÃ©s & ModÃ¨les ImplÃ©mentÃ©s

### ğŸ§© ModÃ¨les SupportÃ©s

| ModÃ¨le | Type | Description |
|--------|------|-------------|
| **HypER** | Convolutionnel + Hypernetwork | GÃ©nÃ¨re dynamiquement les filtres de convolution Ã  partir de la relation. TrÃ¨s efficace et lÃ©ger. |
| **ConvE** | Convolutionnel 2D | ConcatÃ¨ne sujet et relation, applique une convolution 2D, puis une couche dense. |
| **DistMult** | Multiplicatif | Score = `sujet âŠ™ relation â‹… objet` â€” simple mais ne gÃ¨re pas lâ€™asymÃ©trie. |
| **ComplEx** | Complexe | Extension de DistMult dans lâ€™espace complexe â€” gÃ¨re les relations asymÃ©triques (ex: â€œparent_deâ€). |
| **HypE** | Convolutionnel paramÃ©trÃ© | Chaque relation a ses propres poids de convolution â€” plus lourd que HypER. |

### ğŸ“Š MÃ©triques dâ€™Ã‰valuation

Le modÃ¨le est Ã©valuÃ© via la tÃ¢che de **Link Prediction** :

Pour chaque triplet `(s, r, o)` dans le jeu de test :
- On masque lâ€™objet `o`
- On prÃ©dit tous les objets possibles
- On calcule le **rang** de lâ€™objet correct parmi les prÃ©dictions

MÃ©triques calculÃ©es :
- **Hits@1, Hits@3, Hits@10** â†’ % de fois oÃ¹ la bonne rÃ©ponse est dans les 1/3/10 premiÃ¨res prÃ©dictions
- **Mean Rank (MR)** â†’ rang moyen de la bonne rÃ©ponse
- **Mean Reciprocal Rank (MRR)** â†’ moyenne de `1/rang` â†’ pÃ©nalise fortement les mauvais rangs

---

## ğŸ§© Technologies & BibliothÃ¨ques

```python
import torch
import numpy as np
from torch.nn import functional as F
from torch.optim import Adam
from torch.optim.lr_scheduler import ExponentialLR
